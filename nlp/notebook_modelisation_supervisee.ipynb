{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic question categorization (modelisation)\n",
    "Pierre-Yves BOISBUNON - February 2018\n",
    "\n",
    "----------\n",
    "\n",
    "In this notebook, we will continue the categorization job to establish classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "from __future__ import division\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Import clean dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First open previously stored cleaned dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Body</th>\n",
       "      <th>Title</th>\n",
       "      <th>Tags</th>\n",
       "      <th>y</th>\n",
       "      <th>raw</th>\n",
       "      <th>raw_letter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;p&gt;I have two dataframes that I'm trying to co...</td>\n",
       "      <td>How to combine two differently multi-indexed p...</td>\n",
       "      <td>python|pandas</td>\n",
       "      <td>python pandas</td>\n",
       "      <td>I have two dataframes that I'm trying to combi...</td>\n",
       "      <td>have two dataframes that try to combine they e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;p&gt;I have Eclipse CDT Oxygen on Ubuntu 16.04, ...</td>\n",
       "      <td>Eclipse CDT Oxygen with LLVM support forces st...</td>\n",
       "      <td>c++|llvm|ubuntu-16.04|eclipse-cdt|clang++</td>\n",
       "      <td>c++</td>\n",
       "      <td>I have Eclipse CDT Oxygen on Ubuntu 16.04, wit...</td>\n",
       "      <td>have eclipse cdt oxygen on ubuntu with the llv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>&lt;p&gt;I use ' SelectionMode : Row ' now&lt;/p&gt;\\n\\n&lt;p...</td>\n",
       "      <td>How to get selected row in C1flexgrid?</td>\n",
       "      <td>c#|c1flexgrid</td>\n",
       "      <td>c#</td>\n",
       "      <td>I use ' SelectionMode : Row ' now\\n\\nI already...</td>\n",
       "      <td>use selectionmode row now already use mousecli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>&lt;p&gt;So I have 24 \"person\" objects, which I crea...</td>\n",
       "      <td>Javascript, map returns undefined</td>\n",
       "      <td>javascript|arrays|object|dictionary</td>\n",
       "      <td>javascript arrays</td>\n",
       "      <td>So I have 24 \"person\" objects, which I created...</td>\n",
       "      <td>so have person object which create use name ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>&lt;p&gt;I want to extract only jms message text wit...</td>\n",
       "      <td>Extract jms text content</td>\n",
       "      <td>java|jms|message-queue</td>\n",
       "      <td>java</td>\n",
       "      <td>I want to extract only jms message text withou...</td>\n",
       "      <td>want to extract only jms message text without ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               Body  \\\n",
       "0      0  <p>I have two dataframes that I'm trying to co...   \n",
       "1      2  <p>I have Eclipse CDT Oxygen on Ubuntu 16.04, ...   \n",
       "2      3  <p>I use ' SelectionMode : Row ' now</p>\\n\\n<p...   \n",
       "3      5  <p>So I have 24 \"person\" objects, which I crea...   \n",
       "4      6  <p>I want to extract only jms message text wit...   \n",
       "\n",
       "                                               Title  \\\n",
       "0  How to combine two differently multi-indexed p...   \n",
       "1  Eclipse CDT Oxygen with LLVM support forces st...   \n",
       "2             How to get selected row in C1flexgrid?   \n",
       "3                  Javascript, map returns undefined   \n",
       "4                           Extract jms text content   \n",
       "\n",
       "                                        Tags                  y  \\\n",
       "0                              python|pandas      python pandas   \n",
       "1  c++|llvm|ubuntu-16.04|eclipse-cdt|clang++                c++   \n",
       "2                              c#|c1flexgrid                 c#   \n",
       "3        javascript|arrays|object|dictionary  javascript arrays   \n",
       "4                     java|jms|message-queue               java   \n",
       "\n",
       "                                                 raw  \\\n",
       "0  I have two dataframes that I'm trying to combi...   \n",
       "1  I have Eclipse CDT Oxygen on Ubuntu 16.04, wit...   \n",
       "2  I use ' SelectionMode : Row ' now\\n\\nI already...   \n",
       "3  So I have 24 \"person\" objects, which I created...   \n",
       "4  I want to extract only jms message text withou...   \n",
       "\n",
       "                                          raw_letter  \n",
       "0  have two dataframes that try to combine they e...  \n",
       "1  have eclipse cdt oxygen on ubuntu with the llv...  \n",
       "2  use selectionmode row now already use mousecli...  \n",
       "3  so have person object which create use name ar...  \n",
       "4  want to extract only jms message text without ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset_clean.csv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import cleanly **y** column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [python, pandas]\n",
       "1                   [c++]\n",
       "2                    [c#]\n",
       "3    [javascript, arrays]\n",
       "4                  [java]\n",
       "Name: y, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['y'] = df['y'].apply(lambda x: x.split())\n",
    "df['y'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a **random state** in order models are computed with the same values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random state in order to force computation with the same results\n",
    "random_state = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Utils functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the  **plot_learning_curve** function used later in the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "# http://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5),\n",
    "                       scoring=None):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - An object to be used as a cross-validation generator.\n",
    "          - An iterable yielding train/test splits.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes,\n",
    "        scoring=scoring)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the **EstimatorSelectionHelper** class used for cross validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "class EstimatorSelectionHelper:\n",
    "    \"\"\"\n",
    "    Custom class for cross validation computation.\n",
    "    It takes as parameters:\n",
    "    - models and their associated parameters\n",
    "    \"\"\"\n",
    "    def __init__(self, models, params):\n",
    "        if not set(models.keys()).issubset(set(params.keys())):\n",
    "            missing_params = list(set(models.keys()) - set(params.keys()))\n",
    "            raise ValueError(\"Some estimators are missing parameters: %s\" % missing_params)\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "    \n",
    "    def fit(self, X, y, cv=5, n_jobs=1, verbose=1, scoring=None):\n",
    "        for key in self.keys:\n",
    "            print(\"Running GridSearchCV for %s.\" % key)\n",
    "            model = self.models[key]\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs, \n",
    "                              verbose=verbose, scoring=scoring)\n",
    "            gs.fit(X,y)\n",
    "            self.grid_searches[key] = gs   \n",
    "                \n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, train_score, test_score, std_test_score, params):\n",
    "            d = {\n",
    "                 'estimator': key,\n",
    "                 'train_score': train_score,\n",
    "                 'test_score': test_score,\n",
    "                 'std_test_score': std_test_score * 2\n",
    "            }\n",
    "            d_copy = d.copy()\n",
    "            d_copy.update(params)\n",
    "            return pd.Series(d_copy)\n",
    "                      \n",
    "        rows = [row(k, train_score, test_score, std_test_score, params) \n",
    "                    for k in helper.keys\n",
    "                     for train_score, test_score, std_test_score, params \n",
    "                        in zip(self.grid_searches[k].cv_results_['mean_train_score'],\n",
    "                               self.grid_searches[k].cv_results_['mean_test_score'], \n",
    "                               self.grid_searches[k].cv_results_['std_test_score'],\n",
    "                               self.grid_searches[k].cv_results_['params'])]\n",
    "        df = pd.concat(rows, axis=1).T#.sort([sort_by], ascending=False)\n",
    "        \n",
    "        columns = ['estimator', 'train_score', 'test_score', 'std_test_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "        \n",
    "        return df[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define our custom scorer based on **f1 macro** computation: metrics used for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def tag_scorer(y_test,y_predict):\n",
    "    \"\"\"\n",
    "    Function defining custom scorer based on f1 macro metric\n",
    "    \"\"\"\n",
    "    f1_score = precision_recall_fscore_support(y_test, y_predict, average = 'macro')[2]\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Supervised method for tags prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the modelisation, we wil use three different classifiers:\n",
    "- LinearSVC classifier\n",
    "- Random Forest classifier\n",
    "- XGBoost classifier\n",
    "\n",
    "\n",
    "Let's first optimize optimize feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Optimize feature selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binarize y\n",
      "Bag of words vectorizer\n",
      "Create train/test patterns\n"
     ]
    }
   ],
   "source": [
    "# Create X and y vectors\n",
    "y = df['y'].tolist()\n",
    "X = df[\"raw_letter\"]\n",
    "\n",
    "# Binarize y\n",
    "print(\"Binarize y\")\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_trans = mlb.fit_transform(y)\n",
    "\n",
    "# Bag of word vectorizer\n",
    "print(\"Bag of words vectorizer\")\n",
    "vect = CountVectorizer(stop_words='english', \n",
    "                       lowercase=True, \n",
    "                       tokenizer=lambda x: x.split(' '),\n",
    "                       max_df=0.2, min_df=100)\n",
    "tfidf = TfidfTransformer(use_idf=True, norm='l2')\n",
    "pipeline_vect_tfidf = Pipeline([\n",
    "    ('vect', vect),\n",
    "    ('tfidf', tfidf)\n",
    "])\n",
    "X_tf = pipeline_vect_tfidf.fit_transform(X)\n",
    "\n",
    "# Create train/test patterns\n",
    "print(\"Create train/test patterns\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tf, y_trans,\n",
    "                                                    random_state=random_state, \n",
    "                                                    test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start first with **LinearSVC** model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for OVR_SVC.\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>clf__estimator__dual</th>\n",
       "      <th>clf__estimator__penalty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OVR_SVC</td>\n",
       "      <td>0.772902</td>\n",
       "      <td>0.69956</td>\n",
       "      <td>0.00836339</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OVR_SVC</td>\n",
       "      <td>0.823042</td>\n",
       "      <td>0.689399</td>\n",
       "      <td>0.00890963</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  estimator train_score test_score std_test_score clf__estimator__dual  \\\n",
       "0   OVR_SVC    0.772902    0.69956     0.00836339                False   \n",
       "1   OVR_SVC    0.823042   0.689399     0.00890963                False   \n",
       "\n",
       "  clf__estimator__penalty  \n",
       "0                      l1  \n",
       "1                      l2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model classifier\n",
    "clf = OneVsRestClassifier(estimator=LinearSVC(random_state=random_state, dual=False, penalty='l1'))\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'clf__estimator__penalty': ('l1', 'l2'),\n",
    "    'clf__estimator__dual': [False]\n",
    "}\n",
    "\n",
    "models = { \n",
    "    'OVR_SVC': pipeline\n",
    "}\n",
    "\n",
    "params = { \n",
    "    'OVR_SVC': [parameters]\n",
    "}\n",
    "\n",
    "helper = EstimatorSelectionHelper(models, params)\n",
    "helper.fit(X_train, y_train, n_jobs=-1, scoring='f1_macro')\n",
    "model_result = helper.score_summary(sort_by='min_score')\n",
    "model_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7052799800691859"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "y_predict = helper.grid_searches['OVR_SVC'].predict(X_test)\n",
    "y_predict = np.array(y_predict)\n",
    "f1_score(y_predict, y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best hyperparameter found is penality/dual equal to **l1/False** with a test score equal to **0.70**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 RandomForest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to optimize Random Forest model, we will optimize the model in 3 steps:\n",
    "- Step 1: Setup number of estimators.\n",
    "- Step 2: Setup best split point.\n",
    "- Step 3: Setup max_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Tune n_estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start tuning **n_estimators**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for OVR_RF.\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed: 109.9min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>clf__estimator__n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OVR_RF</td>\n",
       "      <td>0.998565</td>\n",
       "      <td>0.615273</td>\n",
       "      <td>0.0112692</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OVR_RF</td>\n",
       "      <td>0.99988</td>\n",
       "      <td>0.622283</td>\n",
       "      <td>0.00899853</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OVR_RF</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.622077</td>\n",
       "      <td>0.0037976</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  estimator train_score test_score std_test_score clf__estimator__n_estimators\n",
       "0    OVR_RF    0.998565   0.615273      0.0112692                           50\n",
       "1    OVR_RF     0.99988   0.622283     0.00899853                          100\n",
       "2    OVR_RF    0.999998   0.622077      0.0037976                          200"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rfc = RandomForestClassifier(random_state=random_state)\n",
    "\n",
    "clf = OneVsRestClassifier(estimator=model_rfc, n_jobs=-1)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'clf__estimator__n_estimators': [50,100,200]\n",
    "}\n",
    "\n",
    "models = { \n",
    "    'OVR_RF': pipeline\n",
    "}\n",
    "\n",
    "params = { \n",
    "    'OVR_RF': [parameters]\n",
    "}\n",
    "\n",
    "helper = EstimatorSelectionHelper(models, params)\n",
    "helper.fit(X_train, y_train, n_jobs=-1, scoring='f1_macro')\n",
    "model_result = helper.score_summary(sort_by='min_score')\n",
    "model_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep a number of estimators of **50** as it seems there is not a lot of difference in the test_score.\n",
    "We can observe also a huge level of overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Tune min_samples_split and min_samples_leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to optimize min_samples_split/min_samples_leaf to reduce the overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for OVR_RF.\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 108.1min\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed: 224.7min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>clf__estimator__min_samples_leaf</th>\n",
       "      <th>clf__estimator__min_samples_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OVR_RF</td>\n",
       "      <td>0.738917</td>\n",
       "      <td>0.560742</td>\n",
       "      <td>0.0110107</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OVR_RF</td>\n",
       "      <td>0.738917</td>\n",
       "      <td>0.560742</td>\n",
       "      <td>0.0110107</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OVR_RF</td>\n",
       "      <td>0.738917</td>\n",
       "      <td>0.560742</td>\n",
       "      <td>0.0110107</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OVR_RF</td>\n",
       "      <td>0.738917</td>\n",
       "      <td>0.560742</td>\n",
       "      <td>0.0110107</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OVR_RF</td>\n",
       "      <td>0.738917</td>\n",
       "      <td>0.560742</td>\n",
       "      <td>0.0110107</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OVR_RF</td>\n",
       "      <td>0.735258</td>\n",
       "      <td>0.559425</td>\n",
       "      <td>0.00357937</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>OVR_RF</td>\n",
       "      <td>0.656381</td>\n",
       "      <td>0.530978</td>\n",
       "      <td>0.0115247</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OVR_RF</td>\n",
       "      <td>0.656381</td>\n",
       "      <td>0.530978</td>\n",
       "      <td>0.0115247</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OVR_RF</td>\n",
       "      <td>0.656381</td>\n",
       "      <td>0.530978</td>\n",
       "      <td>0.0115247</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OVR_RF</td>\n",
       "      <td>0.656381</td>\n",
       "      <td>0.530978</td>\n",
       "      <td>0.0115247</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>OVR_RF</td>\n",
       "      <td>0.656381</td>\n",
       "      <td>0.530978</td>\n",
       "      <td>0.0115247</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>OVR_RF</td>\n",
       "      <td>0.656381</td>\n",
       "      <td>0.530978</td>\n",
       "      <td>0.0115247</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>OVR_RF</td>\n",
       "      <td>0.59903</td>\n",
       "      <td>0.506867</td>\n",
       "      <td>0.0133047</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>OVR_RF</td>\n",
       "      <td>0.59903</td>\n",
       "      <td>0.506867</td>\n",
       "      <td>0.0133047</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>OVR_RF</td>\n",
       "      <td>0.59903</td>\n",
       "      <td>0.506867</td>\n",
       "      <td>0.0133047</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>OVR_RF</td>\n",
       "      <td>0.59903</td>\n",
       "      <td>0.506867</td>\n",
       "      <td>0.0133047</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>OVR_RF</td>\n",
       "      <td>0.59903</td>\n",
       "      <td>0.506867</td>\n",
       "      <td>0.0133047</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>OVR_RF</td>\n",
       "      <td>0.59903</td>\n",
       "      <td>0.506867</td>\n",
       "      <td>0.0133047</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   estimator train_score test_score std_test_score  \\\n",
       "0     OVR_RF    0.738917   0.560742      0.0110107   \n",
       "1     OVR_RF    0.738917   0.560742      0.0110107   \n",
       "2     OVR_RF    0.738917   0.560742      0.0110107   \n",
       "3     OVR_RF    0.738917   0.560742      0.0110107   \n",
       "4     OVR_RF    0.738917   0.560742      0.0110107   \n",
       "5     OVR_RF    0.735258   0.559425     0.00357937   \n",
       "6     OVR_RF    0.656381   0.530978      0.0115247   \n",
       "7     OVR_RF    0.656381   0.530978      0.0115247   \n",
       "8     OVR_RF    0.656381   0.530978      0.0115247   \n",
       "9     OVR_RF    0.656381   0.530978      0.0115247   \n",
       "10    OVR_RF    0.656381   0.530978      0.0115247   \n",
       "11    OVR_RF    0.656381   0.530978      0.0115247   \n",
       "12    OVR_RF     0.59903   0.506867      0.0133047   \n",
       "13    OVR_RF     0.59903   0.506867      0.0133047   \n",
       "14    OVR_RF     0.59903   0.506867      0.0133047   \n",
       "15    OVR_RF     0.59903   0.506867      0.0133047   \n",
       "16    OVR_RF     0.59903   0.506867      0.0133047   \n",
       "17    OVR_RF     0.59903   0.506867      0.0133047   \n",
       "\n",
       "   clf__estimator__min_samples_leaf clf__estimator__min_samples_split  \n",
       "0                                 3                                 2  \n",
       "1                                 3                                 3  \n",
       "2                                 3                                 4  \n",
       "3                                 3                                 5  \n",
       "4                                 3                                 6  \n",
       "5                                 3                                 7  \n",
       "6                                 4                                 2  \n",
       "7                                 4                                 3  \n",
       "8                                 4                                 4  \n",
       "9                                 4                                 5  \n",
       "10                                4                                 6  \n",
       "11                                4                                 7  \n",
       "12                                5                                 2  \n",
       "13                                5                                 3  \n",
       "14                                5                                 4  \n",
       "15                                5                                 5  \n",
       "16                                5                                 6  \n",
       "17                                5                                 7  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rfc = RandomForestClassifier(random_state=random_state, n_estimators=50)\n",
    "\n",
    "clf = OneVsRestClassifier(estimator=model_rfc, n_jobs=-1)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'clf__estimator__min_samples_split': [2, 3, 4, 5, 6, 7],\n",
    "    'clf__estimator__min_samples_leaf': [3, 4, 5]\n",
    "}\n",
    "\n",
    "models = { \n",
    "    'OVR_RF': pipeline\n",
    "}\n",
    "\n",
    "params = { \n",
    "    'OVR_RF': [parameters]\n",
    "}\n",
    "\n",
    "helper = EstimatorSelectionHelper(models, params)\n",
    "helper.fit(X_train, y_train, n_jobs=-1, scoring='f1_macro')\n",
    "model_result = helper.score_summary(sort_by='min_score')\n",
    "model_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! We reduce the overfit. The best couple for min_samples_split/min_samples_leaf seems to be **3/6**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 Tune max_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's tune now the max_features to optimize the test_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for OVR_RF.\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed: 430.9min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>clf__estimator__max_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OVR_RF</td>\n",
       "      <td>0.55492</td>\n",
       "      <td>0.482247</td>\n",
       "      <td>0.0134742</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OVR_RF</td>\n",
       "      <td>0.55492</td>\n",
       "      <td>0.482247</td>\n",
       "      <td>0.0134742</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OVR_RF</td>\n",
       "      <td>0.151034</td>\n",
       "      <td>0.125634</td>\n",
       "      <td>0.00454774</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OVR_RF</td>\n",
       "      <td>0.816664</td>\n",
       "      <td>0.717229</td>\n",
       "      <td>0.00772181</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  estimator train_score test_score std_test_score clf__estimator__max_features\n",
       "0    OVR_RF     0.55492   0.482247      0.0134742                         auto\n",
       "1    OVR_RF     0.55492   0.482247      0.0134742                         sqrt\n",
       "2    OVR_RF    0.151034   0.125634     0.00454774                         log2\n",
       "3    OVR_RF    0.816664   0.717229     0.00772181                         None"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rfc = RandomForestClassifier(random_state=random_state, \n",
    "                                   n_estimators=50,\n",
    "                                   min_samples_split=3,\n",
    "                                   min_samples_leaf=6)\n",
    "\n",
    "clf = OneVsRestClassifier(estimator=model_rfc, n_jobs=-1)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'clf__estimator__max_features': ['auto', 'sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "models = { \n",
    "    'OVR_RF': pipeline\n",
    "}\n",
    "\n",
    "params = { \n",
    "    'OVR_RF': [parameters]\n",
    "}\n",
    "\n",
    "helper = EstimatorSelectionHelper(models, params)\n",
    "helper.fit(X_train, y_train, n_jobs=-1, scoring='f1_macro')\n",
    "model_result = helper.score_summary(sort_by='min_score')\n",
    "model_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7285733770054947"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "y_predict = helper.grid_searches['OVR_RF'].predict(X_test)\n",
    "y_predict = np.array(y_predict)\n",
    "f1_score(y_predict, y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finaly, if we observe the model is correctly optimized reducing at the best the overfit.\n",
    "Let's try to optimize the test_score, specifiy a threshold of probability of the prediction of the RF model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7235358018996912,\n",
       " 0.7392861492575606,\n",
       " 0.7394146609302844,\n",
       " 0.7285733770054947]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba = helper.grid_searches['OVR_RF'].predict_proba(X_test)\n",
    "y_proba = np.array(y_proba)\n",
    "from sklearn.metrics import f1_score\n",
    "threshold = [0.2,0.3,0.4,0.5]\n",
    "score = []\n",
    "for thresh in threshold:\n",
    "    y_predict = np.zeros((y_proba.shape[0], y_proba.shape[1]))\n",
    "    for i in range(0, y_proba.shape[0]):\n",
    "        for j in range(0, len(y_proba[i,:])):\n",
    "            #y_predict[i,j] = 0\n",
    "            if (y_proba[i,j] > thresh):\n",
    "                y_predict[i,j] = 1\n",
    "    score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A threshold equal to **0.4** gives the best validation score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to optimize XGBoost model, we will optimize the model in 3 steps:\n",
    "- Step 1: Setup number of estimators.\n",
    "- Step 2: Setup max depth (node number) and min_child_weight.\n",
    "- Step 3: Setup learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Tuning n_estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's tune first the number of estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for OVR_XGB.\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed: 411.5min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>clf__estimator__n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OVR_XGB</td>\n",
       "      <td>0.719879</td>\n",
       "      <td>0.683509</td>\n",
       "      <td>0.00749604</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OVR_XGB</td>\n",
       "      <td>0.827344</td>\n",
       "      <td>0.722333</td>\n",
       "      <td>0.0081886</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OVR_XGB</td>\n",
       "      <td>0.880932</td>\n",
       "      <td>0.727059</td>\n",
       "      <td>0.00947631</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  estimator train_score test_score std_test_score clf__estimator__n_estimators\n",
       "0   OVR_XGB    0.719879   0.683509     0.00749604                           10\n",
       "1   OVR_XGB    0.827344   0.722333      0.0081886                           50\n",
       "2   OVR_XGB    0.880932   0.727059     0.00947631                          100"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# See http://xgboost.readthedocs.io/en/latest/parameter.html\n",
    "estimator = xgb.XGBClassifier(\n",
    "              nthread=4,\n",
    "              objective='multi:softprob',\n",
    "              learning_rate=0.3,\n",
    "              silent=1, \n",
    "              num_class=30,\n",
    "              seed=random_state)\n",
    "\n",
    "model_rfc = OneVsRestClassifier(estimator=estimator, n_jobs=-1)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('clf', model_rfc)\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'clf__estimator__n_estimators': [10, 50, 100]\n",
    "}\n",
    "\n",
    "models = { \n",
    "    'OVR_XGB': pipeline\n",
    "}\n",
    "\n",
    "params = { \n",
    "    'OVR_XGB': [parameters]\n",
    "}\n",
    "\n",
    "helper = EstimatorSelectionHelper(models, params)\n",
    "helper.fit(X_train, y_train, n_jobs=-1, scoring='f1_macro')\n",
    "model_result = helper.score_summary(sort_by='min_score')\n",
    "model_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there is not a lor of differences between 50 and 100 estimators, let's choose **50** estimators that should help in CPU calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Tune max_depth and min_child_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to optimize validation score and reduce the overfit, optimizing max_depth and min_child_weight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for OVR_XGB.\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# See http://xgboost.readthedocs.io/en/latest/parameter.html\n",
    "estimator = xgb.XGBClassifier(\n",
    "              nthread=4,\n",
    "              objective='multi:softprob',\n",
    "              learning_rate=0.3,\n",
    "              silent=1, \n",
    "              num_class=30,\n",
    "              n_estimators=50,\n",
    "              seed=random_state)\n",
    "\n",
    "model_xgb = OneVsRestClassifier(estimator=estimator, n_jobs=-1)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('clf', model_xgb)\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'clf__estimator__max_depth': [4,6,8],\n",
    "    'clf__estimator__min_child_weight':[1,4]\n",
    "}\n",
    "\n",
    "models = { \n",
    "    'OVR_XGB': pipeline\n",
    "}\n",
    "\n",
    "params = { \n",
    "    'OVR_XGB': [parameters]\n",
    "}\n",
    "\n",
    "helper = EstimatorSelectionHelper(models, params)\n",
    "helper.fit(X_train, y_train, n_jobs=-1, scoring='f1_macro')\n",
    "model_result = helper.score_summary(sort_by='min_score')\n",
    "model_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the best **max_depth** / **min_child_weight** couple is **4/4**, it gives the best cross validation score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.6 Tune learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to optimize also learning_rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# See http://xgboost.readthedocs.io/en/latest/parameter.html\n",
    "estimator = xgb.XGBClassifier(\n",
    "              nthread=4,\n",
    "              objective='multi:softprob',\n",
    "              learning_rate=0.3,\n",
    "              silent=1, \n",
    "              num_class=30,\n",
    "              n_estimators=50,\n",
    "              max_depth=4,\n",
    "              min_child_weight=4,\n",
    "              seed=random_state)\n",
    "\n",
    "model_xgb = OneVsRestClassifier(estimator=estimator, n_jobs=-1)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('clf', model_xgb)\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'clf__estimator__learning_rate':[0.1,0.3,0.4]\n",
    "}\n",
    "\n",
    "models = { \n",
    "    'OVR_XGB': pipeline\n",
    "}\n",
    "\n",
    "params = { \n",
    "    'OVR_XGB': [parameters]\n",
    "}\n",
    "\n",
    "helper = EstimatorSelectionHelper(models, params)\n",
    "helper.fit(X_train, y_train, n_jobs=-1, scoring='f1_macro')\n",
    "model_result = helper.score_summary(sort_by='min_score')\n",
    "model_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the best **learning rate** value is **0.3**, it gives the best cross validation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.grid_searches['OVR_XGB'].best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = helper.grid_searches['OVR_XGB'].predict_proba(X_test)\n",
    "y_proba = np.array(y_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finaly, if we observe the model is correctly optimized reducing at the best the overfit.\n",
    "Let's try to optimize the test_score, specifiy a threshold of probability of the prediction of the XGB model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "#label_ranking_average_precision_score\n",
    "threshold = [0.05,0.1,0.4,0.5]\n",
    "score = []\n",
    "for thresh in threshold:\n",
    "    y_predict = np.zeros((y_proba.shape[0], y_proba.shape[1]))\n",
    "    for i in range(0, y_proba.shape[0]):\n",
    "        for j in range(0, len(y_proba[i,:])):\n",
    "            #y_predict[i,j] = 0\n",
    "            if (y_proba[i,j] > thresh):\n",
    "                y_predict[i,j] = 1\n",
    "    score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A threshold equal to **0.4** gives the best test score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3 Select final supervised-model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the previous job completed, we have the following results:\n",
    "- LinearSVC model:\n",
    "    - Training score: 0.77\n",
    "    - Cross validation score: 0.69\n",
    "    - Test validation score: 0.70\n",
    "    - % overfit: 11%\n",
    "- Random Forest model:\n",
    "    - Training score: 0.81\n",
    "    - Cross validation score: 0.72\n",
    "    - Test validation score: 0.71\n",
    "    - % overfit: 12%\n",
    "- XGBoost model:\n",
    "    - Training score: 0.84\n",
    "    - Cross validation score: 0.73\n",
    "    - Test validation score: 0.74\n",
    "    - % overfit: 15%\n",
    "\n",
    "We choose to select **Random Forest** classifier giving best test validation score result with lowest overfit percent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
